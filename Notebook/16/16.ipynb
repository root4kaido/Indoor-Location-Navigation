{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM baseline\n",
    "\n",
    "from kuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sys.path.append('../../')\n",
    "import src.utils as utils\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/Indoor-Location-Navigation/data/\")\n",
    "WIFI_DIR = DATA_DIR / 'indoorunifiedwifids'\n",
    "MLFLOW_DIR = DATA_DIR / 'mlflow/mlruns'\n",
    "OUTPUT_DIR = Path('./output/')\n",
    "MLFLOW_DIR = DATA_DIR / 'mlflow/mlruns'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'loss':{\n",
    "        'name': 'MSELoss',\n",
    "        'params':{}\n",
    "    },\n",
    "    'optimizer':{\n",
    "        'name': 'Adam',\n",
    "        'params':{\n",
    "            'lr': 0.001,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'scheduler':{\n",
    "        'name': 'ReduceLROnPlateau',\n",
    "        'params':{\n",
    "            'factor': 0.1,\n",
    "            'patience': 3,\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'loader':{\n",
    "        'train':{\n",
    "            'batch_size': 512,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 4,\n",
    "        },\n",
    "        'valid':{\n",
    "            'batch_size': 512,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 4,\n",
    "        },\n",
    "        'test':{\n",
    "            'batch_size': 512,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 4,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "config = configs\n",
    "\n",
    "# globals variable\n",
    "SEED = 777\n",
    "MAX_EPOCHS = 200\n",
    "N_SPLITS = 5\n",
    "DEBUG = False\n",
    "# EXP_MESSAGE = config['globals']['exp_message']\n",
    "\n",
    "EXP_NAME = 16\n",
    "IS_SAVE = True\n",
    "\n",
    "utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: wandb: not found\n"
     ]
    }
   ],
   "source": [
    "!wandb login e8aaf98060af90035c3c28a83b34452780aeec20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(WIFI_DIR / 'train_all.csv')\n",
    "test_df = pd.read_csv(WIFI_DIR / 'test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DATA_DIR/'indoor-location-navigation/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BSSIDとRSSIは100ずつ存在しているけど全てが必要なわけではないみたい  \n",
    "ここでは20だけ取り出している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training target features\n",
    "NUM_FEATS = 80\n",
    "BSSID_FEATS = [f'bssid_{i}' for i in range(NUM_FEATS)]\n",
    "RSSI_FEATS  = [f'rssi_{i}' for i in range(NUM_FEATS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rssi_0</th>\n",
       "      <th>rssi_1</th>\n",
       "      <th>rssi_2</th>\n",
       "      <th>rssi_3</th>\n",
       "      <th>rssi_4</th>\n",
       "      <th>rssi_5</th>\n",
       "      <th>rssi_6</th>\n",
       "      <th>rssi_7</th>\n",
       "      <th>rssi_8</th>\n",
       "      <th>rssi_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "      <td>-48</td>\n",
       "      <td>-49</td>\n",
       "      <td>-51</td>\n",
       "      <td>-52</td>\n",
       "      <td>-54</td>\n",
       "      <td>-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-29</td>\n",
       "      <td>-34</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "      <td>-48</td>\n",
       "      <td>-49</td>\n",
       "      <td>-52</td>\n",
       "      <td>-52</td>\n",
       "      <td>-52</td>\n",
       "      <td>-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-33</td>\n",
       "      <td>-39</td>\n",
       "      <td>-48</td>\n",
       "      <td>-48</td>\n",
       "      <td>-49</td>\n",
       "      <td>-52</td>\n",
       "      <td>-54</td>\n",
       "      <td>-55</td>\n",
       "      <td>-55</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-46</td>\n",
       "      <td>-48</td>\n",
       "      <td>-49</td>\n",
       "      <td>-50</td>\n",
       "      <td>-51</td>\n",
       "      <td>-52</td>\n",
       "      <td>-54</td>\n",
       "      <td>-56</td>\n",
       "      <td>-57</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-42</td>\n",
       "      <td>-49</td>\n",
       "      <td>-51</td>\n",
       "      <td>-51</td>\n",
       "      <td>-52</td>\n",
       "      <td>-53</td>\n",
       "      <td>-54</td>\n",
       "      <td>-55</td>\n",
       "      <td>-55</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258120</th>\n",
       "      <td>-53</td>\n",
       "      <td>-63</td>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-68</td>\n",
       "      <td>-68</td>\n",
       "      <td>-68</td>\n",
       "      <td>-68</td>\n",
       "      <td>-70</td>\n",
       "      <td>-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258121</th>\n",
       "      <td>-58</td>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-67</td>\n",
       "      <td>-68</td>\n",
       "      <td>-68</td>\n",
       "      <td>-69</td>\n",
       "      <td>-70</td>\n",
       "      <td>-71</td>\n",
       "      <td>-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258122</th>\n",
       "      <td>-57</td>\n",
       "      <td>-58</td>\n",
       "      <td>-60</td>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-67</td>\n",
       "      <td>-68</td>\n",
       "      <td>-69</td>\n",
       "      <td>-71</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258123</th>\n",
       "      <td>-58</td>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-66</td>\n",
       "      <td>-68</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-71</td>\n",
       "      <td>-71</td>\n",
       "      <td>-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258124</th>\n",
       "      <td>-64</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-71</td>\n",
       "      <td>-71</td>\n",
       "      <td>-72</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258125 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rssi_0  rssi_1  rssi_2  rssi_3  rssi_4  rssi_5  rssi_6  rssi_7  \\\n",
       "0          -32     -39     -47     -48     -48     -49     -51     -52   \n",
       "1          -29     -34     -47     -48     -48     -49     -52     -52   \n",
       "2          -33     -39     -48     -48     -49     -52     -54     -55   \n",
       "3          -46     -48     -49     -50     -51     -52     -54     -56   \n",
       "4          -42     -49     -51     -51     -52     -53     -54     -55   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "258120     -53     -63     -64     -66     -68     -68     -68     -68   \n",
       "258121     -58     -64     -66     -67     -68     -68     -69     -70   \n",
       "258122     -57     -58     -60     -64     -66     -67     -68     -69   \n",
       "258123     -58     -64     -66     -66     -68     -69     -69     -71   \n",
       "258124     -64     -69     -69     -71     -71     -72     -73     -73   \n",
       "\n",
       "        rssi_8  rssi_9  \n",
       "0          -54     -56  \n",
       "1          -52     -53  \n",
       "2          -55     -55  \n",
       "3          -57     -57  \n",
       "4          -55     -55  \n",
       "...        ...     ...  \n",
       "258120     -70     -71  \n",
       "258121     -71     -71  \n",
       "258122     -71     -73  \n",
       "258123     -71     -72  \n",
       "258124     -73     -73  \n",
       "\n",
       "[258125 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:, 100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bssid_NはN個目のBSSIDを示しておりRSSI値が大きい順に番号が振られている。\n",
    "100個しかない\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSSID TYPES(train): 61206\n",
      "BSSID TYPES(test): 33042\n",
      "BSSID TYPES(all): 94248\n"
     ]
    }
   ],
   "source": [
    "# get numbers of bssids to embed them in a layer\n",
    "\n",
    "# train\n",
    "wifi_bssids = []\n",
    "# bssidを列ごとにリストに入れていく\n",
    "for i in range(100):\n",
    "    wifi_bssids.extend(train_df.iloc[:,i].values.tolist())\n",
    "wifi_bssids = list(set(wifi_bssids))\n",
    "\n",
    "train_wifi_bssids_size = len(wifi_bssids)\n",
    "print(f'BSSID TYPES(train): {train_wifi_bssids_size}')\n",
    "\n",
    "# test\n",
    "wifi_bssids_test = []\n",
    "for i in range(100):\n",
    "    wifi_bssids_test.extend(test_df.iloc[:,i].values.tolist())\n",
    "wifi_bssids_test = list(set(wifi_bssids_test))\n",
    "\n",
    "test_wifi_bssids_size = len(wifi_bssids_test)\n",
    "print(f'BSSID TYPES(test): {test_wifi_bssids_size}')\n",
    "\n",
    "\n",
    "wifi_bssids.extend(wifi_bssids_test)\n",
    "wifi_bssids_size = len(wifi_bssids)\n",
    "print(f'BSSID TYPES(all): {wifi_bssids_size}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bssid_0</th>\n",
       "      <th>bssid_1</th>\n",
       "      <th>bssid_2</th>\n",
       "      <th>bssid_3</th>\n",
       "      <th>bssid_4</th>\n",
       "      <th>bssid_5</th>\n",
       "      <th>bssid_6</th>\n",
       "      <th>bssid_7</th>\n",
       "      <th>bssid_8</th>\n",
       "      <th>bssid_9</th>\n",
       "      <th>...</th>\n",
       "      <th>rssi_95</th>\n",
       "      <th>rssi_96</th>\n",
       "      <th>rssi_97</th>\n",
       "      <th>rssi_98</th>\n",
       "      <th>rssi_99</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>floor</th>\n",
       "      <th>path</th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52392</td>\n",
       "      <td>35870</td>\n",
       "      <td>2764</td>\n",
       "      <td>34897</td>\n",
       "      <td>52709</td>\n",
       "      <td>35259</td>\n",
       "      <td>42719</td>\n",
       "      <td>33509</td>\n",
       "      <td>23416</td>\n",
       "      <td>15248</td>\n",
       "      <td>...</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>107.85044</td>\n",
       "      <td>161.892620</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e1580adf4c3420006d520d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35870</td>\n",
       "      <td>52392</td>\n",
       "      <td>7486</td>\n",
       "      <td>34897</td>\n",
       "      <td>52709</td>\n",
       "      <td>35259</td>\n",
       "      <td>21970</td>\n",
       "      <td>15248</td>\n",
       "      <td>17024</td>\n",
       "      <td>5350</td>\n",
       "      <td>...</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>-79</td>\n",
       "      <td>-80</td>\n",
       "      <td>-80</td>\n",
       "      <td>107.85044</td>\n",
       "      <td>161.892620</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e1580adf4c3420006d520d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35870</td>\n",
       "      <td>52392</td>\n",
       "      <td>52709</td>\n",
       "      <td>34897</td>\n",
       "      <td>35259</td>\n",
       "      <td>23416</td>\n",
       "      <td>49407</td>\n",
       "      <td>6672</td>\n",
       "      <td>7486</td>\n",
       "      <td>48500</td>\n",
       "      <td>...</td>\n",
       "      <td>-77</td>\n",
       "      <td>-78</td>\n",
       "      <td>-78</td>\n",
       "      <td>-78</td>\n",
       "      <td>-78</td>\n",
       "      <td>98.33065</td>\n",
       "      <td>163.343340</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e1580adf4c3420006d520d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23416</td>\n",
       "      <td>34897</td>\n",
       "      <td>35259</td>\n",
       "      <td>52392</td>\n",
       "      <td>35870</td>\n",
       "      <td>3706</td>\n",
       "      <td>49407</td>\n",
       "      <td>15612</td>\n",
       "      <td>10166</td>\n",
       "      <td>4977</td>\n",
       "      <td>...</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-76</td>\n",
       "      <td>-77</td>\n",
       "      <td>-77</td>\n",
       "      <td>98.33065</td>\n",
       "      <td>163.343340</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e1580adf4c3420006d520d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35870</td>\n",
       "      <td>35259</td>\n",
       "      <td>23416</td>\n",
       "      <td>19472</td>\n",
       "      <td>52392</td>\n",
       "      <td>3706</td>\n",
       "      <td>49407</td>\n",
       "      <td>18305</td>\n",
       "      <td>21409</td>\n",
       "      <td>52794</td>\n",
       "      <td>...</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-76</td>\n",
       "      <td>-77</td>\n",
       "      <td>-77</td>\n",
       "      <td>98.33065</td>\n",
       "      <td>163.343340</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e1580adf4c3420006d520d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258120</th>\n",
       "      <td>35065</td>\n",
       "      <td>14545</td>\n",
       "      <td>16494</td>\n",
       "      <td>21326</td>\n",
       "      <td>50465</td>\n",
       "      <td>22830</td>\n",
       "      <td>943</td>\n",
       "      <td>30429</td>\n",
       "      <td>43802</td>\n",
       "      <td>32684</td>\n",
       "      <td>...</td>\n",
       "      <td>-84</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>122.68994</td>\n",
       "      <td>124.028015</td>\n",
       "      <td>6</td>\n",
       "      <td>5dcd5c88a4dbe7000630b084</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258121</th>\n",
       "      <td>35065</td>\n",
       "      <td>16494</td>\n",
       "      <td>21326</td>\n",
       "      <td>943</td>\n",
       "      <td>50465</td>\n",
       "      <td>22830</td>\n",
       "      <td>30059</td>\n",
       "      <td>33363</td>\n",
       "      <td>59581</td>\n",
       "      <td>14545</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>127.17589</td>\n",
       "      <td>123.677780</td>\n",
       "      <td>6</td>\n",
       "      <td>5dcd5c88a4dbe7000630b084</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258122</th>\n",
       "      <td>943</td>\n",
       "      <td>35065</td>\n",
       "      <td>14545</td>\n",
       "      <td>16494</td>\n",
       "      <td>21326</td>\n",
       "      <td>22830</td>\n",
       "      <td>50465</td>\n",
       "      <td>30059</td>\n",
       "      <td>48476</td>\n",
       "      <td>59581</td>\n",
       "      <td>...</td>\n",
       "      <td>-84</td>\n",
       "      <td>-84</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>127.17589</td>\n",
       "      <td>123.677780</td>\n",
       "      <td>6</td>\n",
       "      <td>5dcd5c88a4dbe7000630b084</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258123</th>\n",
       "      <td>14545</td>\n",
       "      <td>16494</td>\n",
       "      <td>35065</td>\n",
       "      <td>21326</td>\n",
       "      <td>50465</td>\n",
       "      <td>943</td>\n",
       "      <td>30059</td>\n",
       "      <td>48476</td>\n",
       "      <td>58803</td>\n",
       "      <td>22830</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>127.17589</td>\n",
       "      <td>123.677780</td>\n",
       "      <td>6</td>\n",
       "      <td>5dcd5c88a4dbe7000630b084</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258124</th>\n",
       "      <td>16494</td>\n",
       "      <td>30059</td>\n",
       "      <td>943</td>\n",
       "      <td>58803</td>\n",
       "      <td>48476</td>\n",
       "      <td>22830</td>\n",
       "      <td>35065</td>\n",
       "      <td>59581</td>\n",
       "      <td>50465</td>\n",
       "      <td>7967</td>\n",
       "      <td>...</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>-85</td>\n",
       "      <td>130.08112</td>\n",
       "      <td>122.490820</td>\n",
       "      <td>6</td>\n",
       "      <td>5dcd5c88a4dbe7000630b084</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258125 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bssid_0  bssid_1  bssid_2  bssid_3  bssid_4  bssid_5  bssid_6  \\\n",
       "0         52392    35870     2764    34897    52709    35259    42719   \n",
       "1         35870    52392     7486    34897    52709    35259    21970   \n",
       "2         35870    52392    52709    34897    35259    23416    49407   \n",
       "3         23416    34897    35259    52392    35870     3706    49407   \n",
       "4         35870    35259    23416    19472    52392     3706    49407   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "258120    35065    14545    16494    21326    50465    22830      943   \n",
       "258121    35065    16494    21326      943    50465    22830    30059   \n",
       "258122      943    35065    14545    16494    21326    22830    50465   \n",
       "258123    14545    16494    35065    21326    50465      943    30059   \n",
       "258124    16494    30059      943    58803    48476    22830    35065   \n",
       "\n",
       "        bssid_7  bssid_8  bssid_9  ...  rssi_95  rssi_96  rssi_97  rssi_98  \\\n",
       "0         33509    23416    15248  ...      -79      -79      -79      -79   \n",
       "1         15248    17024     5350  ...      -79      -79      -79      -80   \n",
       "2          6672     7486    48500  ...      -77      -78      -78      -78   \n",
       "3         15612    10166     4977  ...      -75      -76      -76      -77   \n",
       "4         18305    21409    52794  ...      -75      -76      -76      -77   \n",
       "...         ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "258120    30429    43802    32684  ...      -84      -85      -85      -85   \n",
       "258121    33363    59581    14545  ...      -85      -85      -85      -85   \n",
       "258122    30059    48476    59581  ...      -84      -84      -85      -85   \n",
       "258123    48476    58803    22830  ...      -85      -85      -85      -85   \n",
       "258124    59581    50465     7967  ...      -85      -85      -85      -85   \n",
       "\n",
       "        rssi_99          x           y  floor                      path  \\\n",
       "0           -79  107.85044  161.892620     -1  5e1580adf4c3420006d520d4   \n",
       "1           -80  107.85044  161.892620     -1  5e1580adf4c3420006d520d4   \n",
       "2           -78   98.33065  163.343340     -1  5e1580adf4c3420006d520d4   \n",
       "3           -77   98.33065  163.343340     -1  5e1580adf4c3420006d520d4   \n",
       "4           -77   98.33065  163.343340     -1  5e1580adf4c3420006d520d4   \n",
       "...         ...        ...         ...    ...                       ...   \n",
       "258120      -85  122.68994  124.028015      6  5dcd5c88a4dbe7000630b084   \n",
       "258121      -85  127.17589  123.677780      6  5dcd5c88a4dbe7000630b084   \n",
       "258122      -85  127.17589  123.677780      6  5dcd5c88a4dbe7000630b084   \n",
       "258123      -85  127.17589  123.677780      6  5dcd5c88a4dbe7000630b084   \n",
       "258124      -85  130.08112  122.490820      6  5dcd5c88a4dbe7000630b084   \n",
       "\n",
       "        site_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "258120       23  \n",
       "258121       23  \n",
       "258122       23  \n",
       "258123       23  \n",
       "258124       23  \n",
       "\n",
       "[258125 rows x 205 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess\n",
    "\n",
    "class Preprocess:\n",
    "    \n",
    "    def __init__(self, train_df):\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(wifi_bssids)\n",
    "        self.le_site = LabelEncoder()\n",
    "        self.le_site.fit(train_df['site_id'])\n",
    "\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(train_df.loc[:,RSSI_FEATS])\n",
    "        \n",
    "        tmps = []\n",
    "        for i in BSSID_FEATS:\n",
    "            tmps.append(self.le.transform(train_df.loc[:,i]))\n",
    "        tmps = np.array(tmps).T\n",
    "\n",
    "        self.ss_b = StandardScaler()\n",
    "        self.ss_b.fit(tmps)\n",
    "\n",
    "    def do(self, input_df):\n",
    "\n",
    "\n",
    "        output_df = input_df.copy()\n",
    "        # RSSIの正規化\n",
    "        output_df.loc[:,RSSI_FEATS] = self.ss.transform(input_df.loc[:,RSSI_FEATS])\n",
    "        # BSSIDのLE(1からふる)\n",
    "        for i in BSSID_FEATS:\n",
    "            output_df.loc[:,i] = self.le.transform(input_df.loc[:,i])\n",
    "#         output_df.loc[:,BSSID_FEATS] = self.ss_b.transform(output_df.loc[:,BSSID_FEATS])\n",
    "\n",
    "        # site_idのLE\n",
    "        output_df.loc[:, 'site_id'] = self.le_site.transform(input_df.loc[:, 'site_id'])\n",
    "\n",
    "        return output_df\n",
    "    \n",
    "preprocess = Preprocess(train_df)   \n",
    "\n",
    "train = preprocess.do(train_df)\n",
    "test = preprocess.do(test_df)\n",
    "\n",
    "train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_count = len(train['site_id'].unique())\n",
    "site_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch model\n",
    "- embedding layerが重要  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'db01605eac3f33540038bd9722aba25774871d43'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[BSSID_FEATS].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class IndoorDataset(Dataset):\n",
    "    def __init__(self, df, phase='train'):\n",
    "        self.df = df\n",
    "        self.phase = phase\n",
    "        self.bssid_feats = df[BSSID_FEATS].values.astype(np.float32)\n",
    "        self.rssi_feats = df[RSSI_FEATS].values.astype(np.float32)\n",
    "        self.site_id = df['site_id'].values.astype(int)\n",
    "\n",
    "        if phase in ['train', 'valid']:\n",
    "            self.xy = df[['x', 'y']].values.astype(np.float32)\n",
    "            self.floor = df['floor'].values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        feature = {\n",
    "            'BSSID_FEATS':self.bssid_feats[idx],\n",
    "            'RSSI_FEATS':self.rssi_feats[idx],\n",
    "            'site_id':self.site_id[idx]\n",
    "        }\n",
    "        if self.phase in ['train', 'valid']:\n",
    "            target = {\n",
    "                'xy':self.xy[idx],\n",
    "                'floor':self.floor[idx]\n",
    "            }\n",
    "        else:\n",
    "            target = {}\n",
    "        return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.BatchNorm1d(80*ninp),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(80*ninp, 2),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.flatten(output)\n",
    "        output = self.linear_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = 94248 # the size of vocabulary\n",
    "emsize = 2 # embedding dimension\n",
    "nhid = 100 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Fold 0\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "oofs = []  # 全てのoofをdfで格納する\n",
    "predictions = []  # 全ての予測値をdfで格納する\n",
    "val_scores = []\n",
    "# skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "# for fold, (trn_idx, val_idx) in enumerate(skf.split(train.loc[:, 'path'], train.loc[:, 'path'])):\n",
    "for fold, (trn_idx, val_idx) in enumerate(gkf.split(train.loc[:, 'path'], groups=train.loc[:, 'path'])):\n",
    "\n",
    "    # 指定したfoldのみループを回す\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Fold {fold}')\n",
    "    print('=' * 20)\n",
    "\n",
    "    # train/valid data\n",
    "    trn_df = train.loc[trn_idx, BSSID_FEATS + RSSI_FEATS + ['site_id', 'x','y','floor']].reset_index(drop=True)\n",
    "    val_df = train.loc[val_idx, BSSID_FEATS + RSSI_FEATS + ['site_id', 'x','y','floor']].reset_index(drop=True)\n",
    "\n",
    "    # data loader\n",
    "    loaders = {}\n",
    "    loader_config = config[\"loader\"]\n",
    "    loaders[\"train\"] = DataLoader(IndoorDataset(trn_df, phase=\"train\"), **loader_config[\"train\"], worker_init_fn=worker_init_fn) \n",
    "    loaders[\"valid\"] = DataLoader(IndoorDataset(val_df, phase=\"valid\"), **loader_config[\"valid\"], worker_init_fn=worker_init_fn)\n",
    "    loaders[\"test\"] = DataLoader(IndoorDataset(test, phase=\"test\"), **loader_config[\"test\"], worker_init_fn=worker_init_fn)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in loaders[\"train\"]:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-223036db3215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BSSID_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BSSID_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout)\n",
    "src_mask = model.generate_square_subsequent_mask(x['BSSID_FEATS'].size(0))\n",
    "model(x['BSSID_FEATS'].to(torch.float32), src_mask.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_position_error(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n",
    "\n",
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module, config: dict):\n",
    "    optimizer_config = config[\"optimizer\"]\n",
    "    optimizer_name = optimizer_config.get(\"name\")\n",
    "    base_optimizer_name = optimizer_config.get(\"base_name\")\n",
    "    optimizer_params = optimizer_config['params']\n",
    "\n",
    "    if hasattr(optim, optimizer_name):\n",
    "        optimizer = optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_params)\n",
    "        return optimizer\n",
    "    else:\n",
    "        base_optimizer = optim.__getattribute__(base_optimizer_name)\n",
    "        optimizer = globals().get(optimizer_name)(\n",
    "            model.parameters(), \n",
    "            base_optimizer,\n",
    "            **optimizer_config[\"params\"])\n",
    "        return  optimizer\n",
    "\n",
    "def get_scheduler(optimizer, config: dict):\n",
    "    scheduler_config = config[\"scheduler\"]\n",
    "    scheduler_name = scheduler_config.get(\"name\")\n",
    "\n",
    "    if scheduler_name is None:\n",
    "        return\n",
    "    else:\n",
    "        return optim.lr_scheduler.__getattribute__(scheduler_name)(\n",
    "            optimizer, **scheduler_config[\"params\"])\n",
    "\n",
    "\n",
    "def get_criterion(config: dict):\n",
    "    loss_config = config[\"loss\"]\n",
    "    loss_name = loss_config[\"name\"]\n",
    "    loss_params = {} if loss_config.get(\"params\") is None else loss_config.get(\"params\")\n",
    "    if hasattr(nn, loss_name):\n",
    "        criterion = nn.__getattribute__(loss_name)(**loss_params)\n",
    "    else:\n",
    "        criterion = globals().get(loss_name)(**loss_params)\n",
    "\n",
    "    return criterion\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner class(pytorch-lighting)\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.xy_criterion = get_criterion(config)\n",
    "        self.f_criterion = get_criterion(config)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x['BSSID_FEATS']\n",
    "        src_mask =self.model.generate_square_subsequent_mask(x.size(0)).to(device)\n",
    "        output = self.model(x, src_mask)\n",
    "#         output = self.model(x)\n",
    "        loss = self.xy_criterion(output[\"xy\"], y[\"xy\"])\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x['BSSID_FEATS']\n",
    "        src_mask =self.model.generate_square_subsequent_mask(x.size(0)).to(device)\n",
    "        output = self.model(x, src_mask)\n",
    "        xy_loss = self.xy_criterion(output[\"xy\"], y[\"xy\"])\n",
    "        f_loss = self.f_criterion(output[\"floor\"], y[\"floor\"])\n",
    "        loss = xy_loss  # + f_loss\n",
    "        mpe = mean_position_error(\n",
    "            to_np(output['xy'][:, 0]), to_np(output['xy'][:, 1]), 0, \n",
    "            to_np(y['xy'][:, 0]), to_np(y['xy'][:, 1]), 0)\n",
    "        \n",
    "        # floor lossは現状は無視して良い\n",
    "        self.log(f'Loss/val', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Loss/xy', xy_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Loss/floor', f_loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'MPE/val', mpe, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return mpe\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = np.mean(outputs)\n",
    "        print(f'epoch = {self.current_epoch}, mpe_loss = {avg_loss}')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = get_optimizer(self.model, self.config)\n",
    "        scheduler = get_scheduler(optimizer, self.config)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"Loss/val\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof\n",
    "def evaluate(model, loaders, phase):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    f_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loaders[phase]:\n",
    "            x, y = batch\n",
    "            x = x['BSSID_FEATS']\n",
    "            src_mask =model.generate_square_subsequent_mask(x.size(0)).to(device)\n",
    "            output = model(x, src_mask)\n",
    "            x_list.append(to_np(output['xy'][:, 0]))\n",
    "            y_list.append(to_np(output['xy'][:, 1]))\n",
    "            f_list.append(to_np(output['floor']))\n",
    "\n",
    "    x_list = np.concatenate(x_list)\n",
    "    y_list = np.concatenate(y_list)\n",
    "    f_list = np.concatenate(f_list)\n",
    "    return x_list, y_list, f_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Fold 0\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2kapcfk5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15924<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/16/wandb/run-20210408_185610-2kapcfk5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/16/wandb/run-20210408_185610-2kapcfk5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">spring-glade-108</strong>: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/2kapcfk5\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/2kapcfk5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2kapcfk5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ruby-dust-109</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/2n30n5yj\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/2n30n5yj</a><br/>\n",
       "                Run data is saved locally in <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/16/wandb/run-20210408_200507-2n30n5yj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/user/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | model        | TransformerModel | 472 K \n",
      "1 | xy_criterion | MSELoss          | 0     \n",
      "2 | f_criterion  | MSELoss          | 0     \n",
      "--------------------------------------------------\n",
      "472 K     Trainable params\n",
      "0         Non-trainable params\n",
      "472 K     Total params\n",
      "1.892     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a525331a44224a638b7a470c971688b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f650146b8d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-588105c5d7ba>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mxy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mf_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"floor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"floor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-fd6feea44e5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mninp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "oofs = []  # 全てのoofをdfで格納する\n",
    "predictions = []  # 全ての予測値をdfで格納する\n",
    "val_scores = []\n",
    "# skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "# for fold, (trn_idx, val_idx) in enumerate(skf.split(train.loc[:, 'path'], train.loc[:, 'path'])):\n",
    "for fold, (trn_idx, val_idx) in enumerate(gkf.split(train.loc[:, 'path'], groups=train.loc[:, 'path'])):\n",
    "\n",
    "    # 指定したfoldのみループを回す\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Fold {fold}')\n",
    "    print('=' * 20)\n",
    "\n",
    "    # train/valid data\n",
    "    trn_df = train.loc[trn_idx, BSSID_FEATS + RSSI_FEATS + ['site_id', 'x','y','floor']].reset_index(drop=True)\n",
    "    val_df = train.loc[val_idx, BSSID_FEATS + RSSI_FEATS + ['site_id', 'x','y','floor']].reset_index(drop=True)\n",
    "\n",
    "    # data loader\n",
    "    loaders = {}\n",
    "    loader_config = config[\"loader\"]\n",
    "    loaders[\"train\"] = DataLoader(IndoorDataset(trn_df, phase=\"train\"), **loader_config[\"train\"], worker_init_fn=worker_init_fn) \n",
    "    loaders[\"valid\"] = DataLoader(IndoorDataset(val_df, phase=\"valid\"), **loader_config[\"valid\"], worker_init_fn=worker_init_fn)\n",
    "    loaders[\"test\"] = DataLoader(IndoorDataset(test, phase=\"test\"), **loader_config[\"test\"], worker_init_fn=worker_init_fn)\n",
    "    \n",
    "    # model\n",
    "    model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout)\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    # loggers\n",
    "    RUN_NAME = f'exp{str(EXP_NAME)}'\n",
    "    wandb.init(project='Indoor_Location_Navigation', entity='sqrt4kaido', group=RUN_NAME, job_type=RUN_NAME + f'-fold-{fold}')\n",
    "    wandb.run.name = RUN_NAME + f'-fold-{fold}'\n",
    "    wandb_config = wandb.config\n",
    "    wandb_config.model_name = model_name\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    \n",
    "    loggers = []\n",
    "    loggers.append(WandbLogger())\n",
    "\n",
    "    learner = Learner(model, config)\n",
    "    \n",
    "    # callbacks\n",
    "    callbacks = []\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=f'Loss/val',\n",
    "        mode='min',\n",
    "        dirpath=OUTPUT_DIR,\n",
    "        verbose=False,\n",
    "        filename=f'{model_name}-{learner.current_epoch}-{fold}')\n",
    "    callbacks.append(checkpoint_callback)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='Loss/val',\n",
    "        min_delta=0.00,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        mode='min')\n",
    "    callbacks.append(early_stop_callback)\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=loggers,\n",
    "        checkpoint_callback=callbacks,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        default_root_dir=OUTPUT_DIR,\n",
    "        gpus=1,\n",
    "        fast_dev_run=DEBUG,\n",
    "        deterministic=True,\n",
    "        benchmark=True,\n",
    "#         precision=16,\n",
    "#         progress_bar_refresh_rate=0  # vscodeの時progress barの動作が遅いので表示しない\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.fit(learner, train_dataloader=loaders['train'], val_dataloaders=loaders['valid'])\n",
    "\n",
    "    #############\n",
    "    # validation (to make oof)\n",
    "    #############\n",
    "    model.eval()\n",
    "    oof_x, oof_y, oof_f = evaluate(model, loaders, phase=\"valid\")\n",
    "    val_df[\"oof_x\"] = oof_x\n",
    "    val_df[\"oof_y\"] = oof_y\n",
    "    val_df[\"oof_floor\"] = oof_f\n",
    "    oofs.append(val_df)\n",
    "    \n",
    "    val_score = mean_position_error(\n",
    "        val_df[\"oof_x\"].values, val_df[\"oof_y\"].values, 0,\n",
    "        val_df['x'].values, val_df['y'].values, 0)\n",
    "    val_scores.append(val_score)\n",
    "    print(f\"fold {fold}: mean position error {val_score}\")\n",
    "\n",
    "    #############\n",
    "    # inference\n",
    "    #############\n",
    "    preds_x, preds_y, preds_f = evaluate(model, loaders, phase=\"test\")\n",
    "    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n",
    "    test_preds.columns = sub.columns\n",
    "    test_preds[\"site_path_timestamp\"] = test[\"site_path_timestamp\"]\n",
    "    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n",
    "    predictions.append(test_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(oofs) > 1:\n",
    "    oofs_df = pd.concat(oofs)\n",
    "else:\n",
    "    oofs_df = oofs[0]\n",
    "oofs_df.to_csv(str(OUTPUT_DIR) + f\"/oof{EXP_NAME}.csv\", index=False)\n",
    "oofs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # foldの結果を平均した後、reindexでsubmission fileにindexを合わせる\n",
    "all_preds = pd.concat(predictions).groupby('site_path_timestamp').mean().reindex(sub.index)\n",
    "\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floorの数値を置換\n",
    "simple_accurate_99 = pd.read_csv('../01/submission.csv')\n",
    "all_preds['floor'] = simple_accurate_99['floor'].values\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.to_csv(str(OUTPUT_DIR) + f\"/sub{EXP_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:8.134229954895378\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV:{np.mean(val_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1en0l7nr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25347<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/05/wandb/run-20210327_180701-1en0l7nr/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/05/wandb/run-20210327_180701-1en0l7nr/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Loss/val</td><td>55.20833</td></tr><tr><td>Loss/xy</td><td>55.20833</td></tr><tr><td>Loss/floor</td><td>4.40498</td></tr><tr><td>MPE/val</td><td>8.26543</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>trainer/global_step</td><td>80799</td></tr><tr><td>_runtime</td><td>957</td></tr><tr><td>_timestamp</td><td>1616836981</td></tr><tr><td>_step</td><td>199</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Loss/val</td><td>█▇▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/xy</td><td>█▇▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/floor</td><td>▆▆▆▆▆▆▅█▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>MPE/val</td><td>█▇▆▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">distinctive-sea-18</strong>: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/1en0l7nr\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/1en0l7nr</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1en0l7nr). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ancient-haze-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/38n2yvxn\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/38n2yvxn</a><br/>\n",
       "                Run data is saved locally in <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/05/wandb/run-20210327_182327-38n2yvxn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 31880<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.49MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.00130087052…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/05/wandb/run-20210327_182327-38n2yvxn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/knikaido/work/Indoor-Location-Navigation/Git/Notebook/05/wandb/run-20210327_182327-38n2yvxn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>CV_score</td><td>8.13423</td></tr><tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1616837013</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>CV_score</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ancient-haze-19</strong>: <a href=\"https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/38n2yvxn\" target=\"_blank\">https://wandb.ai/sqrt4kaido/Indoor_Location_Navigation/runs/38n2yvxn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='Indoor_Location_Navigation', entity='sqrt4kaido', group=RUN_NAME, job_type='summary')\n",
    "wandb.run.name = 'summary'\n",
    "wandb.log({'CV_score': np.mean(val_scores)})\n",
    "wandb.save(utils.get_notebook_path())\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
